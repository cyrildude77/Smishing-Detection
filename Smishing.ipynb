{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ],
      "metadata": {
        "id": "09UHCqU8our9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "Q6cMeQiPouuV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/SMSSmishCollection.txt\", sep='\\t', names=['label', 'text'], encoding='utf-8', on_bad_lines='skip')\n",
        "print (df)\n",
        "df['label'] = df['label'].map({'smish': 1, 'ham': 0})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4U8qjBLouy0",
        "outputId": "04366700-e89a-4189-a801-5bf97a4700e5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      label                                               text\n",
            "0       ham  Go until jurong point, crazy.. Available only ...\n",
            "1       ham                      Ok lar... Joking wif u oni...\n",
            "2     smish  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3       ham  U dun say so early hor... U c already then say...\n",
            "4       ham  Nah I don't think he goes to usf, he lives aro...\n",
            "...     ...                                                ...\n",
            "5567  smish  This is the 2nd time we have tried 2 contact u...\n",
            "5568    ham               Will Ã¼ b going to esplanade fr home?\n",
            "5569    ham  Pity, * was in mood for that. So...any other s...\n",
            "5570    ham  The guy did some bitching but I acted like i'd...\n",
            "5571    ham                         Rofl. Its true to its name\n",
            "\n",
            "[5572 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'http\\S+', ' <URL> ', text)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "df['cleaned_text'] = df['text'].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "FDeug9m3ou1f"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(df['cleaned_text']).toarray()\n",
        "y = df['label'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "k2YDCnV7ou3u"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SMSDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n"
      ],
      "metadata": {
        "id": "cdo7kseCou6A"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(SMSDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(SMSDataset(X_test, y_test), batch_size=32)\n"
      ],
      "metadata": {
        "id": "X7ZrpS-Vou8S"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SmishingLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, num_layers=2, dropout=0.3):\n",
        "        super(SmishingLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc1 = nn.Linear(hidden_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        x = self.fc1(lstm_out[:, -1, :])\n",
        "        x = self.fc2(x)\n",
        "        return self.sigmoid(x)\n"
      ],
      "metadata": {
        "id": "gN447pN8ou-g"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SmishingLSTM(input_dim=X_train.shape[1]).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "tmc-REouovAj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(15):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch).squeeze()\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f'Epoch [{epoch+1}/15], Loss: {total_loss/len(train_loader):.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYyRTkNFovCq",
        "outputId": "e5f9a1c1-0b42-4d03-c7de-6329cb7262f2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/15], Loss: 0.2325\n",
            "Epoch [2/15], Loss: 0.0383\n",
            "Epoch [3/15], Loss: 0.0121\n",
            "Epoch [4/15], Loss: 0.0070\n",
            "Epoch [5/15], Loss: 0.0043\n",
            "Epoch [6/15], Loss: 0.0035\n",
            "Epoch [7/15], Loss: 0.0035\n",
            "Epoch [8/15], Loss: 0.0024\n",
            "Epoch [9/15], Loss: 0.0024\n",
            "Epoch [10/15], Loss: 0.0020\n",
            "Epoch [11/15], Loss: 0.0019\n",
            "Epoch [12/15], Loss: 0.0019\n",
            "Epoch [13/15], Loss: 0.0018\n",
            "Epoch [14/15], Loss: 0.0017\n",
            "Epoch [15/15], Loss: 0.0014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        outputs = model(X_batch).squeeze()\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        correct += (predicted == y_batch).sum().item()\n",
        "        total += y_batch.size(0)\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Test Accuracy: {accuracy:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LKF2ocgovGB",
        "outputId": "8583f6f6-c5d8-4d29-db24-57ed72efc1f6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.97\n"
          ]
        }
      ]
    }
  ]
}